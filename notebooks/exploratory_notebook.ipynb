{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1974ed7e",
   "metadata": {},
   "source": [
    "0. Set up notebook to start from repo root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d68463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benjo\\Documents\\Projects\\wildlife-camtrap-classification\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%cd C:\\Users\\benjo\\Documents\\Projects\\wildlife-camtrap-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fd62b1",
   "metadata": {},
   "source": [
    "1. Data loading and making of manifest\n",
    "Extracts relevant data from the annotations json and converts and saves into a csv for future usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a06243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: C:\\Users\\benjo\\Documents\\Projects\\wildlife-camtrap-classification\n"
     ]
    }
   ],
   "source": [
    "images = r\"data/cct/images\"\n",
    "annotations = r\"data/cct/annotations/caltech_images_20210113.json\"\n",
    "manifest_out = r\"data/cct/manifest.csv\"\n",
    "counts_out = r\"data/cct/class_counts.csv\"\n",
    "missing_out = r\"data/cct/missing_files.txt\"\n",
    "\n",
    "print(\"cwd:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3a52e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifest: data/cct/manifest.csv, Rows:243100\n",
      "Class Counts : data/cct/class_counts.csv\n"
     ]
    }
   ],
   "source": [
    "from src.data.make_manifest import load_coco, make_manifest_rows, write_manifest, write_counts\n",
    "\n",
    "coco = load_coco(annotations)\n",
    "rows,missing = make_manifest_rows(images,coco)\n",
    "write_manifest(rows,manifest_out)\n",
    "write_counts(rows,counts_out)\n",
    "if missing:\n",
    "    with open(missing_out, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(missing))\n",
    "print(f'Manifest: {manifest_out}, Rows:{len(rows)}')\n",
    "print(f'Class Counts : {counts_out}')\n",
    "if missing:\n",
    "    print(f'Missing Files: {missing_out}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e99171",
   "metadata": {},
   "source": [
    "2. Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf248251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel_path    0.0\n",
      "label       0.0\n",
      "location    0.0\n",
      "dtype: float64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from src.data.split_dataset import load_manifest,split_df,summarise_split, save_splits\n",
    "\n",
    "df = load_manifest(manifest_out)\n",
    "df.head()\n",
    "missing_per =(df.isna().sum() / len(df)) * 100\n",
    "print(missing_per)\n",
    "\n",
    "empty = df['label'].astype(str).str.strip() == ''\n",
    "print(empty.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a5bf41",
   "metadata": {},
   "source": [
    "From above cells can see in the dataset no missing label,image or path data which would impede training of model, so no intial changes necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7fd8c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>rows</th>\n",
       "      <th>cols</th>\n",
       "      <th>n_classes</th>\n",
       "      <th>n_groups</th>\n",
       "      <th>empty_count</th>\n",
       "      <th>empty_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>194525</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>107</td>\n",
       "      <td>106431</td>\n",
       "      <td>54.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>30719</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>18274</td>\n",
       "      <td>59.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Val</td>\n",
       "      <td>17652</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>1040</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split    rows  cols  n_classes  n_groups  empty_count  empty_pct\n",
       "0  Train  194525     3         17       107       106431      54.71\n",
       "1   Test   30719     3         16        14        18274      59.49\n",
       "2    Val   17652     3         15        19         1040       5.89"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.data.split_dataset import make_subset\n",
    "\n",
    "df = df[~df['label'].isin(['insect','bat','pig','badger','mountain_lion'])]\n",
    "#AS im using reduced subset need to remove smallest classes present to avoid errors\n",
    "train,val,test = split_df(df,0.8)\n",
    "\n",
    "\n",
    "train = train.copy()\n",
    "val =val.copy()\n",
    "test = test.copy()\n",
    "\n",
    "\n",
    "\n",
    "splits_summary = pd.DataFrame([\n",
    "    summarise_split(train,'Train'),\n",
    "    summarise_split(test,'Test'),\n",
    "    summarise_split(val,'Val')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "splits_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85b706a",
   "metadata": {},
   "source": [
    "Had to create sub-set to allow for training on local machine. Also removed smaller classes to avoid getting errors if only 1 of a specific class in a split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac616a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>rows</th>\n",
       "      <th>cols</th>\n",
       "      <th>n_classes</th>\n",
       "      <th>n_groups</th>\n",
       "      <th>empty_count</th>\n",
       "      <th>empty_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>48631</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>107</td>\n",
       "      <td>26608</td>\n",
       "      <td>54.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>7679</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>4568</td>\n",
       "      <td>59.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Val</td>\n",
       "      <td>4413</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>260</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split   rows  cols  n_classes  n_groups  empty_count  empty_pct\n",
       "0  Train  48631     3         17       107        26608      54.71\n",
       "1   Test   7679     3         16        14         4568      59.49\n",
       "2    Val   4413     3         15        19          260       5.89"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = make_subset(train,0.25)\n",
    "val =make_subset(val,0.25)\n",
    "test = make_subset(test,0.25) \n",
    "\n",
    "splits_summary = pd.DataFrame([\n",
    "    summarise_split(train,'Train'),\n",
    "    summarise_split(test,'Test'),\n",
    "    summarise_split(val,'Val')\n",
    "])\n",
    "\n",
    "\n",
    "save_splits(train,val,test)\n",
    "splits_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d9fa47",
   "metadata": {},
   "source": [
    "Making of Label Map from str to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b5ffeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.labels import counts_to_ids\n",
    "\n",
    "label_map = counts_to_ids(\n",
    "    counts_csv=\"data/cct/class_counts.csv\",\n",
    "    out_json=\"data/cct/labels.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7d14b3",
   "metadata": {},
   "source": [
    "Model intialisation and dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27f645d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benjo\\Documents\\Projects\\wildlife-camtrap-classification\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.models.model import create_model\n",
    "from src.data.dataset import create_dataloader, CCTImageDataset, transform_images\n",
    "\n",
    "train_transform = transform_images(train = True,size = 224)\n",
    "test_val_t = transform_images(train = False,size = 224)\n",
    "img_dir = 'data/cct/images'\n",
    "\n",
    "train_dataset = CCTImageDataset(train,img_dir,label_map,transform= train_transform)\n",
    "test_dataset = CCTImageDataset(test,img_dir,label_map,transform= test_val_t)\n",
    "val_dataset = CCTImageDataset(val,img_dir,label_map,transform= test_val_t)\n",
    "\n",
    "BATCH_size = 32\n",
    "train_loader = create_dataloader(dataset= train_dataset,batch_size=BATCH_size,shuffle=True)\n",
    "val_loader = create_dataloader(dataset=val_dataset,batch_size=BATCH_size,shuffle=False)\n",
    "test_loader = create_dataloader(dataset=test_dataset,batch_size=BATCH_size,shuffle=False)\n",
    "\n",
    "model = create_model(labels_path=\"data/cct/labels.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fce7f518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images batch shape: torch.Size([32, 3, 224, 224])\n",
      "Labels batch shape: torch.Size([32])\n",
      "Image tensor dtype: torch.float32\n",
      "Label tensor dtype: torch.int64\n",
      "Image tensor min value: -2.1179039478302\n",
      "Image tensor max value: 2.640000104904175\n",
      "First 5 labels: tensor([0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Images batch shape: {images.shape}\")\n",
    "print(f\"Labels batch shape: {labels.shape}\")\n",
    "print(f\"Image tensor dtype: {images.dtype}\")\n",
    "print(f\"Label tensor dtype: {labels.dtype}\")\n",
    "\n",
    "print(f\"Image tensor min value: {images.min()}\")\n",
    "print(f\"Image tensor max value: {images.max()}\")\n",
    "\n",
    "print(f\"First 5 labels: {labels[:5]}\")\n",
    "\n",
    "#Checks output of dataloader to ensure it looks approx correct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9711c23",
   "metadata": {},
   "source": [
    "3. Running of Model. Train/Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7100c146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.01748 & Train Accuracy: 82.053\n",
      "Val Loss: 0.04942 & Val Accuracy: 51.598\n",
      "Train Loss: 0.01215 & Train Accuracy: 87.156\n",
      "Val Loss: 0.04789 & Val Accuracy: 54.045\n",
      "Train Loss: 0.01022 & Train Accuracy: 89.219\n",
      "Val Loss: 0.05054 & Val Accuracy: 57.489\n",
      "Train Loss: 0.00871 & Train Accuracy: 90.679\n",
      "Val Loss: 0.04092 & Val Accuracy: 61.160\n",
      "Train Loss: 0.00767 & Train Accuracy: 91.824\n",
      "Val Loss: 0.04301 & Val Accuracy: 59.483\n",
      "Train Loss: 0.00685 & Train Accuracy: 92.595\n",
      "Val Loss: 0.04761 & Val Accuracy: 58.396\n",
      "Train Loss: 0.00616 & Train Accuracy: 93.299\n",
      "Val Loss: 0.04357 & Val Accuracy: 61.636\n"
     ]
    }
   ],
   "source": [
    "from src.train import run,setup_loss_log\n",
    "setup_loss_log('reports/performance_log.csv')\n",
    "\n",
    "run(train_loader,val_loader,model,epochs=10,lr = 1e-3,patience= 3,log_path = 'reports/performance_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079764c",
   "metadata": {},
   "source": [
    "Moving over to metrics notebook to avoid re training with each run\n",
    "\n",
    "TEST SPLIT RAN IN OTHER NOTEBOOK FOR ANALYISIS OF PERFORMANCE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
